{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-Propagation Example\n",
    "## on a neural network with single hidden layer with 3 units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv(\"binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([file,pd.get_dummies(file['rank'],prefix=\"rank\")],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(\"rank\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['gre','gpa']:\n",
    "    mean,stnd=data[field].mean(),data[field].std()\n",
    "    data.loc[:,field]=(data[field]-mean)/stnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset in 7:3 ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=np.random.choice(data.index,size=int(len(data)*0.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test=data.iloc[sample],data.drop(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,targets=data_train.drop('admit',axis=1),data_train['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test,targets_test=data_test.drop('admit',axis=1),data_test['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining activation function and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learnrate=0.004\n",
    "epochs=1000\n",
    "hiddenunits=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr,nf=features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_loss=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_to_hidden=np.random.normal(scale=1/nf**0.5,size=(nf,hiddenunits))\n",
    "weights_to_output=np.random.normal(scale=1/nf**0.5,size=hiddenunits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithm\n",
    "### -Set delta weights,ie weight steps as 0,both of weights to hidden and output layer\n",
    "### - For each record in data:\n",
    "     -Make a forward pass calculating the final output of the network.\n",
    "     -Then calculate the error gradient at the output unit= (target-output)*derivative of the output function\n",
    "     -Propagate errors to the hidden layer's all nodes.Say at unit j,\n",
    "        >Error Gradient at j=Weight_from_j_to_output*Error_Gradient_at_Output*derivative of activation function at node j\n",
    "     -Update the weights steps:\n",
    "       >Weights steps for weights to output from j +=Error_Gradient_at_Output * a_at_j  #a is output from hidden layer unit j\n",
    "        >Weights steps for weights to hidden unit j from i input += Error_Grad_at_j * a_at_i is the input \n",
    "### - Update the weights:\n",
    "       Weights to hidden unit j from i += learnrate * weightstep_at_ij / n_records\n",
    "       Weights from hidden unit j  to output += learnrate * weightstep_at_j / n_records\n",
    "## Repeat these steps for e epochs.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.222010587237634\n",
      "Loss: 0.22197000408413436\n",
      "Loss: 0.22193036714866704\n",
      "Loss: 0.2218916569637991\n",
      "Loss: 0.2218538544827864\n",
      "Loss: 0.22181694106968303\n",
      "Loss: 0.2217808984896947\n",
      "Loss: 0.22174570889979323\n",
      "Loss: 0.22171135483955812\n",
      "Loss: 0.2216778192222626\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    del_w_ij=np.zeros(weights_to_hidden.shape)\n",
    "    del_w_j=np.zeros(weights_to_output.shape)\n",
    "    for x,y in zip(features.values,targets):\n",
    "        hidden_output=sigmoid(np.dot(x,weights_to_hidden))\n",
    "        output=sigmoid(np.dot(hidden_output,weights_to_output))\n",
    "        output_error=y-output\n",
    "        output_errgradient=output_error*output*(1-output)\n",
    "        #Calculating Hidden Layer contribution to the error\n",
    "        errh=np.dot(output_errgradient,weights_to_output)\n",
    "        error_termh=errh * hidden_output *(1-hidden_output)\n",
    "        del_w_ij+=error_termh*x[:,None]\n",
    "        del_w_j+=output_errgradient*hidden_output\n",
    "    weights_to_hidden+=(learnrate*del_w_ij)/nr\n",
    "    weights_to_output+=(learnrate*del_w_j)/nr\n",
    "    \n",
    "    if e % (epochs/10)==0:\n",
    "        houtput=sigmoid(np.dot(x,weights_to_hidden))\n",
    "        output=sigmoid(np.dot(houtput,weights_to_output))\n",
    "        error=targets-output\n",
    "        m2er=np.mean(error**2)\n",
    "        if last_loss and m2er>last_loss:\n",
    "            print(\"Loss Increasing=\",m2er)\n",
    "        else:\n",
    "            print(\"Loss:\",m2er)\n",
    "        last_loss=m2er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Out the Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "hidout=sigmoid(np.dot(features_test,weights_to_hidden))\n",
    "outputtest=sigmoid(np.dot(hidout,weights_to_output))\n",
    "predic=outputtest>0.5\n",
    "accuracy=np.mean(predic==targets_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
